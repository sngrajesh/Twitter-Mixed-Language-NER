# ğŸŒ Predominant Language Detection and NER for Code-Mixed Twitter Data ğŸ“

## ğŸš€ Overview
This project focuses on processing code-mixed Twitter data using state-of-the-art NLP techniques. The pipeline consists of:
1. **ğŸ” Fine-tuned mBERT**: Detecting the predominant language in a given code-mixed tweet.
2. **ğŸŒ NLLB (No Language Left Behind)**: Translating the detected language into a monolingual tweet.
3. **ğŸ“Œ Fine-tuned IndicBERT**: Performing Named Entity Recognition (NER) on the translated tweet using a dataset comprising Hindi, Marathi, Telugu, and Gujarati.

## âš™ï¸ Workflow
### 1. **ğŸ§  Predominant Language Detection**
- Used a fine-tuned **mBERT (Multilingual BERT)** model.
- Trained on **code-mixed Twitter data** from the **Samanantar dataset** to identify the dominant language.

### 2. **ğŸ—£ï¸ Translation to Predominant Language**
- Implemented **NLLB (No Language Left Behind)** to translate tweets into the identified predominant language.
- Ensures high-quality translations while maintaining the original context.

### 3. **ğŸ“ Named Entity Recognition (NER)**
- Employed a **fine-tuned IndicBERT** model.
- Trained on a multilingual dataset covering **Hindi, Marathi, Telugu, and Gujarati**.
- Identifies named entities such as **ğŸ‘¤ Persons, ğŸ¢ Organizations, ğŸ“ Locations, and more**.

## ğŸ“Š Dataset
- The dataset consists of code-mixed tweets with annotations for language detection and named entity recognition.
- **ğŸ“š Samanantar dataset** was used for training the models, ensuring a robust multilingual representation.
- NER dataset includes labeled data in **Hindi, Marathi, Telugu, and Gujarati**.

## ğŸ¯ Model Training
- **ğŸ§© mBERT** fine-tuned for language detection.
- **ğŸŒ NLLB** used for high-quality translations.
- **ğŸ”  IndicBERT** fine-tuned for NER tasks using the annotated dataset.

## ğŸ› ï¸ Installation & Usage
### ğŸ“Œ Prerequisites
Ensure you have the following installed:
- ğŸ Python 3.8+
- ğŸ”¥ PyTorch / TensorFlow
- ğŸ¤— Hugging Face Transformers
- ğŸ“œ SentencePiece
- ğŸ­ Fairseq (for NLLB)

## ğŸ› ï¸ Implementation & Tools
- **Languages & Frameworks: Python 3.8+, PyTorch/TensorFlow, Hugging Face Transformers, SentencePiece, and Fairseq.**
- **Web Deployment: The project is deployed as a Flask web application, which serves as the user interface for real-time processing of code-mixed tweets. The Flask app loads the fine-tuned mBERT, NLLB, and 
     IndicBERT models and exposes a RESTful API for users to submit tweets and retrieve predictions.**
- **Development Platforms: Developed using Python, Jupyter Notebook, and Google Colab.**
- **Hardware Configuration: Tested on systems with NVIDIA RTX 3050Ti GPU, 16 GB RAM, and a Quad-core CPU.**

## ğŸš€ API Deployment with Flask
Our integrated Flask application enables seamless real-time analysis:

- **User Interface: Provides a web-based form for users to input tweets.**
- **Model Serving: Upon receiving an input, the Flask API sequentially applies language detection, translation, and NER to return structured results.**

## ğŸ“ˆ Results
- **âœ… Predominant language detection on Code-Mixed texts**.
- **ğŸŒŸ Improved translation quality** using NLLB.
- **ğŸš€ High performance in NER** for Indic languages.

## ğŸ”® Future Improvements
- ğŸŒ Extend NER to cover more Indic languages.
- ğŸ“¢ Enhance domain adaptation for informal Twitter data.
- ğŸ”„ Improve translation post-processing to preserve code-mixed nuances.

## ğŸ‘¥ Contributors
- **Dhruv Kurliye** - [ğŸ”— Dhruv-Kurliye](https://github.com/Dhruv-Kurliye)
- **Rajesh Singh** - [ğŸ”— sngrajesh](https://github.com/sngrajesh)
- **Hemanshi Ukani** - [ğŸ”— hemanshiukani2908](https://github.com/hemanshiukani2908)
- **Abhinav Seggyam** - [ğŸ”—]()

